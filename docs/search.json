{
  "articles": [
    {
      "path": "adjcurves.html",
      "title": "Adjusted survival curves",
      "author": [
        {
          "name": "Andr√© Moser, CTU Bern, University of Bern",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nReview\nBackground\nExample\nKnowledge from the crystal ball\n\nAnalysis strategy\nDescriptive table\nUnadjusted Kaplan-Meier curve and Cox-modelling\nIPW modelling\n\nConclusion\nData simulation\n\nReview\nThis vignette has not been reviewed (yet) by other statisticians üò±. üíÄ You read it on your own risk üíÄ.\nBackground\nUnadjusted Kaplan-Meier curves from observational data might be biased because of confounding (Cole and Hern√°n (2004)). This vignette introduces the concept of inverse probability (IP) weighted survival curves.\nExample\nWe consider a study population of 10,000 patients who received a medication. 60% of the patients were women. In men, a specific enzym was measured with a probability of 30%, whereas in women have a 5 times higher chance of having the enzym. Those with the enzym were more likely to receive the medication (with a probability of 75%), compared to those without the enyzm (probability of 50%).\nResearch question: What is the effect of the medication on death?\nStudy design: Cohort study\nOutcome of interest: Time to death or end of follow-up\nPredictor of interest: Medication\nConfounders: Sex, enzym\nThe used variables from the data are:\nVariable\nDefinition\nCoding\nfemale\nSex\n1=Women, 0=Men\nenzym\nMeasured enzym\n1=Present, 0=Not present\nmedi\nMedication\n1=Received, 0=Not received\ndeath\nDeath\n1=Death, 0=Alive\nfup\nFollow-up time\nNon-negative number\nKnowledge from the crystal ball\nBecause we simulated the data, we know that medication has no effect on mortality.\nAnalysis strategy\nIP weighting constructs weights which are equal to the probability of an individual‚Äôs treatment (here: receiving the medication) given observed covariates (here: sex and enzym) and creates pseudopopulations in which observed covariates are independent of treatment (i.e.¬†no confounding) (Hern√°n and Robins (2022)).\n\n\n# Required packages\nlibrary(tidyverse)\nlibrary(survey)\nlibrary(survival)\nlibrary(gtsummary)\nlibrary(survminer)\n\n\n\n\n\n\nDescriptive table\nThe table below shows a descriptive summary of the study population, by medication.\n\n\ndata %>% tbl_summary(by=medi, label=list(medi ~ \"Medication\")) \n\n\n\nCharacteristic\n      0, N = 3,6391\n      1, N = 6,3611\n    fup\n8 (3, 17)\n6 (2, 13)death\n1,225 (34%)\n3,064 (48%)enzym\n1,321 (36%)\n3,973 (62%)female\n1,972 (54%)\n4,062 (64%)1 Median (IQR); n (%)\n    \n\nUnadjusted Kaplan-Meier curve and Cox-modelling\nA naive (unadjusted) survival analysis of the data reveals the following Kaplan-Meier plot. We conclude that the medication has an effect on survival.\n\n\nmod <- survfit(Surv(fup, death)~medi, data=data)\nggsurvplot(mod, data=data, palette=c(\"#CC0000\", \"black\"), censor=F)\n\n\n\n\n\n\nmod_cox_unadjusted <- coxph(Surv(fup, death) ~ medi, data = data)\nmod_cox_unadjusted\n\n\nCall:\ncoxph(formula = Surv(fup, death) ~ medi, data = data)\n\n        coef exp(coef) se(coef)     z      p\nmedi 0.50613   1.65887  0.03385 14.95 <2e-16\n\nLikelihood ratio test=238.4  on 1 df, p=< 2.2e-16\nn= 10000, number of events= 4289 \n\nAn unadjusted Cox proportional hazard model shows that patients with medication have 1.7 higher hazard of death compared to those without medication.\n\n\nmod_cox_adjusted <- coxph(Surv(fup, death) ~ medi+enzym+female, data = data)\nmod_cox_adjusted\n\n\nCall:\ncoxph(formula = Surv(fup, death) ~ medi + enzym + female, data = data)\n\n           coef exp(coef) se(coef)      z      p\nmedi    0.01610   1.01623  0.03445  0.467  0.640\nenzym   2.37236  10.72265  0.04703 50.441 <2e-16\nfemale  0.07087   1.07344  0.03552  1.995  0.046\n\nLikelihood ratio test=4221  on 3 df, p=< 2.2e-16\nn= 10000, number of events= 4289 \n\nWhat happens if we adjust for enzym and sex? Then the effect of the medication on death vanish (hazard ratio=1.02).\nIPW modelling\nAn IPW modelling approach construct treatment weights (here medication) given known covariates (here sex and enzym) using a logistic regression model.\n\n\n# IPW denominator\nmod <- glm(medi ~ female+enzym, data=data, family=binomial())\n\ndata$ipw <- NA\n# Probabilty of treatment\ndata$ipw <- predict(mod, data=data, type=\"response\")\n# Probabilty of non-treatment\ndata$ipw[data$medi==0] <- 1-predict(mod, data=data, type=\"response\")[data$medi==0]\n\n\n\nWe construct stabilized weights, since they can provide narrower confidence intervals (Hern√°n and Robins (2022)).\n\n\n# Stabilized weights\nmod0 <- glm(medi ~ 1, data=data, family=binomial())\ndata$ipw0 <- predict(mod0, data=data, type=\"response\")\ndata$ipw0[data$medi==0] <- 1-predict(mod0, data=data, type=\"response\")[data$medi==0]\ndata$ipw <- data$ipw0/data$ipw\n\n\n\nAn IPW adjusted Kaplan-Meier curve reveals that medication has no effect on survival:\n\n\n# Set survey design\nsvy_design <- svydesign(id=~1, weights=~ipw, data=data)\n\n# IPW adjusted Kaplan-Meier\nkm_fit <- svykm(Surv(fup, death) ~ medi, design=svy_design)\n\nkm_df <- data.frame(time=km_fit$`1`$time, surv=km_fit$`1`$surv, strata=\"medi=1\")\nkm_df <- bind_rows(km_df, data.frame(time=km_fit$`0`$time, surv=km_fit$`0`$surv, strata=\"medi=0\"))\nggsurvplot_df(km_df, palette=c(\"#CC0000\", \"black\"), censor=F)\n\n\n\n\n\n\nmod_cox_ipw_adjusted <- svycoxph(Surv(fup, death) ~ medi, design=svy_design)\nsummary(mod_cox_ipw_adjusted)\n\n\nIndependent Sampling design (with replacement)\nsvydesign(id = ~1, weights = ~ipw, data = data)\nCall:\nsvycoxph(formula = Surv(fup, death) ~ medi, design = svy_design)\n\n  n= 10000, number of events= 4289 \n\n        coef exp(coef) se(coef) robust se     z Pr(>|z|)\nmedi 0.01669   1.01683  0.03192   0.03323 0.502    0.616\n\n     exp(coef) exp(-coef) lower .95 upper .95\nmedi     1.017     0.9835    0.9527     1.085\n\nConcordance= 0.502  (se = 0.004 )\nLikelihood ratio test= NA  on 1 df,   p=NA\nWald test            = 0.25  on 1 df,   p=0.6\nScore (logrank) test = NA  on 1 df,   p=NA\n\n  (Note: the likelihood ratio and score tests assume independence of\n     observations within a cluster, the Wald and robust score tests do not).\n\nThis is confirmed by an IPW adjusted Cox regression model (hazard ratio=1.02).\nConclusion\nUnadjusted Kaplan-Meier curves from observational data might be biased because of confounding. IPW adjusted survival curves account for confounding by constructing weights which are proportional to the probability of treatment given known covariates. An advantage of IPW adjusted Kaplan-Meier curves is that they provide marginal survival estimates, in contrast to stratified plots (Cole and Hern√°n (2004)).\nData simulation\n\n\nset.seed(1)\nn <- 10000\n\n# 60% percent women\nfemale <- rbinom(n, 1, 0.6)\n# Men has the enzym with a prob of 0.3; women have\n# a 5 times higher chance of having the enzym\nenzym <- ifelse(runif(n) < plogis(qlogis(0.3)+log(5)*female), 1, 0)\n# Those with enzym receive medication with prob 0.75\nmedi <- ifelse(runif(n) < plogis(log(3)*enzym), 1, 0)\n# Hazard of dying: HR=10 of those with enyzm; No effect for medication\nhaz <- 0.01*exp(log(10)*enzym)\n# Time to death\ntime_to_death <- -log(runif(n))/haz\n# Censoring time: Mean duration 20 days\ncensored <- rweibull(n, 1, 20)\n# Follow-up time\nfup <- pmin(time_to_death, censored)\n# Death\ndeath <- ifelse(time_to_death<=censored, 1, 0)\n# Data\ndata <- data.frame(fup, death, medi, enzym, female)\n\n\n\n\n\n\nCole, Stephen R., and Miguel A. Hern√°n. 2004. ‚ÄúAdjusted Survival Curves with Inverse Probability Weights.‚Äù Computer Methods and Programs in Biomedicine 75 (1): 45‚Äì49. https://doi.org/10.1016/j.cmpb.2003.10.004.\n\n\nHern√°n, MA, and JM Robins. 2022. Causal Inference: What If. Boca Raton: Chapman & Hall/CRC.\n\n\n\n\n",
      "last_modified": "2022-05-10T15:59:34+02:00"
    },
    {
      "path": "BFSeqPrePost.html",
      "title": "Sequential Bayes factor trial design for Gaussian pre-post outcomes",
      "author": [
        {
          "name": "Andr√© Moser, CTU Bern, University of Bern",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nBackground\nModel assumptions\nSimulation assumptions\nGeneral assumptions\nFrequentist assumptions\nBayes assumptions\n\nResults\nFrequentist: Non-sequential fixed-n design\nSequential Bayes factor design\n\nSupplement\nANCOVA example analysis\n\n\nWORK IN PROGRESS\nBackground\nThe article of Gajewski et al. (2022) discusses a two-stage two-endpoint adaptive Bayesian trial design with a continuous primary endpoint and one secondary endpoint. The novelty of the presented study is that the authors specify rules for early stopping for efficacy or futility based on the posterior distribution for both endpoints jointly with the aim that the analysis for the secondary endpoint has enough information: ‚ÄúSpecifically, we are interested in a trial design that tests success of a single primary endpoint (rank) but with the desire to stop the trial only if the single, key secondary endpoint also has adequate information‚Äù (Gajewski et al. (2022)). One limitation of the study from Gajewski et al. (2022) is that the endpoints were defined as the difference between a post-intervention measurement and a pre-intervention measurement. Change scores do not account for baseline differences due to regression to the mean (see for example Vickers and Altman (2001)).\nFelix D. Sch√∂nbrodt and Wagenmakers (2018) proposed sequential Bayes factor designs as an alternative to classical power analyses (Bayesian, Frequentist or hybrid), which rely on prior guesses of effect sizes (and their uncertainty) and decision cut-offs (for example, cut-offs for posterior predictive distributions or type-I error). The Bayes factor is a compelling alternative to the above mentioned design parameters and allows for sequential update in a trial design. Felix D. Sch√∂nbrodt et al. (2017) defined a sequential Bayes factor (SBF) as a Bayes factor which is computed in a sequential setting until an a priori defined level of evidence is reached. SBF designs extend the available tools for power and sample size calculation with the Bayes factor as an index of evidence which is appealing for prospective design analysis.\nIn the current study we use a sequential Bayes factor design for bivariate Gaussian endpoints to investigate operation characteristics of the implemented trial design and compare it to a fixed-n Bayes factor design, a Bayesian design with early stopping rules for efficacy/futility based on posterior predictive distributions and frequentist operation characteristics.\nModel assumptions\nWe assume that measurements for the intervention group (1) and the control group (0) are bivariate Gaussian distributed \\(\\mathbf{Y}_i=(\\mathbf{Y}_{i,0}, \\mathbf{Y}_{i,1})^{\\top} \\sim MV_2(\\mu_i, \\Sigma_i)\\), \\(i=\\{0, 1\\}\\), with parameters\n\\[\n\\mu_i=(\\mu_{i,0}, \\mu_{i,1})^{\\top}, \\quad \\Sigma_0=\\begin{pmatrix} \\sigma_{i,0}^2 & \\sigma_{i,0}\\cdot\\sigma_{i,1}\\cdot\\rho_{i,01} \\\\ \\sigma_{i,0}\\cdot\\sigma_{i,1}\\cdot\\rho_{i,01} & \\sigma_{i,1}^2\\end{pmatrix},\n\\]\nwhere \\(\\mu_{i,0}\\) is the location parameter for the pre-intervention measurement for group \\(i\\), \\(i=\\{0, 1\\}\\), and \\(\\mu_{i,1}\\) is the location parameter for the post-intervention measurement for group \\(i\\), \\(i=\\{0, 1\\}\\). We assume that iid samples of size \\(n_i\\), \\(i=\\{0, 1\\}\\), are drawn such that \\(\\mathbf{Y}_{i,t}=(Y_{i1,t}, \\cdots, Y_{in_i,t})^{\\top}\\), \\(i=\\{0, 1\\}\\), \\(t=\\{0, 1\\}\\).\nTo assess the intervention effect \\(\\beta_1\\) we use an ANCOVA model as follows\n\\[\nY_{il,1} \\sim \\beta_0+\\beta_1\\cdot group+\\beta_2\\cdot Y_{il,0}+\\epsilon_{il}, \\quad i=\\{0, 1\\}, \\ t=\\{0, 1\\},\n\\]\nwith \\(\\epsilon_{il}\\) iid Gaussian distributed.\nSimulation assumptions\nGeneral assumptions\n\n\n\nParameter\nGroup\nValue\nGroup\nValue\nLocation time 0\nIntervention\n0\nControl\n0\nLocation time 1\nIntervention\n0, -0.1, -0.3, -0.5\nControl\n0\nStandard deviation time 0\nIntervention\n1\nControl\n1\nStandard deviation time 1\nIntervention\n1\nControl\n1\nCorrelation time 0/1\nIntervention\n-0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75\nControl\n-0.5\nAccrual rate per week\n-\n0.76 patients\n-\n-\nDropout\nIntervention\n0.1\nControl\n0.1\nHypothesis\nGroup\nValue\nNull\nLocation Intervention/Control\n0\nNull\nCorrelation time 0/1 Intervention/Control\n-0.5\nAlternative\nLocation Intervention\n-0.1, -0.3, -0.5\nAlternative\nCorrelation time 0/1 Intervention\n-0.75, -0.25, 0, 0.25, 0.5, 0.75\nFrequentist assumptions\nType-I error: 0.05\nPower: 0.9\nBayes assumptions\nSkeptical prior on intervention effect: \\(\\beta_1 \\sim N(0, 1)\\)\nPrior on baseline measurement effect: \\(\\beta_2 \\sim N(0, x)\\)\nProbability for any success: \\(P(\\beta_1<0|data)\\)\nProbability for moderate success: \\(P(\\beta_1< -0.05|data)\\)\nResults\nFrequentist: Non-sequential fixed-n design\nWe derive operation characteristics for a non-sequential fixed-n design.\n\n\n\n\n\n\n\n\nn_sim\n\n\nmean_weeks_recruiting\n\n\nplanned_sample_size\n\n\nmean_observed_sample_size\n\n\nalpha\n\n\npower\n\n\n1000\n\n\n538.487\n\n\n410\n\n\n368.75\n\n\n0.046\n\n\n0.807\n\n\nBased on 1000 simulations the mean observed sample size (that is, accounting for dropouts) is 369 with an average type-I error of 0.05 and a power of 0.81. The average number of weeks of recruitment was 539.\nSequential Bayes factor design\n\n\n\n\n\n1\n\n\nn_sim\n\n\nmean_sample_size\n\n\nmedian_sample_size\n\n\nprop_max_sample_size\n\n\nmean_bf_primary\n\n\nmean_posterior_any_success\n\n\nmean_posterior_moderate_success\n\n\nfreq_power\n\n\n1\n\n\n10\n\n\n216\n\n\n180\n\n\n0\n\n\n11.123\n\n\n0.997\n\n\n0.991\n\n\n1\n\n\nSupplement\nANCOVA example analysis\nVickers and Altman (2001) provide the rationale for an ANCOVA analysis. As illustrative example we consider a situation where pre-intervention and post-intervention measurements are drawn from a bivariate normal distribution for each group separately (that is, the standard deviation and correlation can differ for each group). Let us assume that this is the systolic blood pressure measured in mmHg. For group 0 we assume that before the intervention the measurements have a mean value of \\(120\\) mmHg and after the intervention a mean value of \\(125\\) mmHg. The standard deviations for both time points are equal to \\(20\\) and the correlation between the time points is \\(-0.75\\), that is,\n\\[\n\\mu_0=(120, 125)^{\\top}, \\quad \\Sigma_0=\\begin{pmatrix} 20^2 & -20^2\\cdot0.75 \\\\ -20^2\\cdot0.75 & 20^2\\end{pmatrix},\n\\]\nwhere \\(\\Sigma_0\\) denotes the covariance matrix.\nFor group 1 we assume\n\\[\n\\mu_1=(115, 100)^{\\top}, \\quad \\Sigma_1=\\begin{pmatrix} 30^2 & -30\\cdot35\\cdot0.5 \\\\ -30\\cdot35\\cdot0.5 & 35\\end{pmatrix}.\n\\]\nAn ANCOVA model uses a linear regression with the post-intervention measurements as outcome, group allocation as predictor and adjusts for pre-intervention measurements.\n\n\nlibrary(mvtnorm)\nlibrary(tidyverse)\n\n# Seed\nset.seed(1)\n\n# Sample size\nn <- 100\n\n# Parameters group 0\nmu_t0 <- 120\nmu_t1 <- 125\nsd_t0 <- 20\nsd_t1 <- 20\ncor_t0_t1 <- -0.75\n\ncov_mat <- matrix(c(sd_t0^2, sd_t0*sd_t1*cor_t0_t1, \n                    sd_t0*sd_t1*cor_t0_t1, sd_t1^2), ncol=2)\ny_0 <- rmvnorm(n, mean=c(mu_t0, mu_t1), sigma=cov_mat)\n\n# Parameters group 1\nmu_t0 <- 115\nmu_t1 <- 100\nsd_t0 <- 30\nsd_t1 <- 35\ncor_t0_t1 <- -0.5\n\ncov_mat <- matrix(c(sd_t0^2, sd_t0*sd_t1*cor_t0_t1, \n                    sd_t0*sd_t1*cor_t0_t1, sd_t1^2), ncol=2)\ny_1 <- rmvnorm(n, mean=c(mu_t0, mu_t1), sigma=cov_mat)\n\n# Data preperation\ndata0 <- data.frame(y_0=y_0[,1], y_1=y_0[,2], group=0)\ndata1 <- data.frame(y_0=y_1[,1], y_1=y_1[,2], group=1)\n\ndata <- bind_rows(data0, data1)\n\n# Frequentist ANCOVA model\nmod <- lm(y_1 ~ group+y_0, data=data)\nsummary(mod)$coeff[,1:2]\n\n               Estimate Std. Error\n(Intercept) 200.6653553 8.07231036\ngroup       -25.3486898 3.28965492\ny_0          -0.6286902 0.06379281\n\n\n\n\nGajewski, Byron J, Bruce F Kimler, Devin C Koestler, Dinesh Pal Mudaranthakam, Kate Young, and Carol J Fabian. 2022. ‚ÄúA novel Bayesian adaptive design incorporating both primary and secondary endpoints for randomized IIB chemoprevention study of women at increased risk for breast cancer.‚Äù Trials 23 (1): 981. https://doi.org/10.1186/s13063-022-06930-5.\n\n\nSch√∂nbrodt, Felix D., Eric-Jan Wagenmakers, Michael Zehetleitner, and Marco Perugini. 2017. ‚ÄúSequential hypothesis testing with Bayes factors: Efficiently testing mean differences.‚Äù Psychological Methods 22 (2): 322‚Äì39. https://doi.org/10.1037/met0000061.\n\n\nSch√∂nbrodt, Felix D, and Eric-Jan Wagenmakers. 2018. ‚ÄúBayes factor design analysis: Planning for compelling evidence.‚Äù Psychonomic Bulletin & Review 25 (1): 128‚Äì42. https://doi.org/10.3758/s13423-017-1230-y.\n\n\nVickers, Andrew J, and Douglas G Altman. 2001. ‚ÄúAnalysing Controlled Trials with Baseline and Follow up Measurements.‚Äù BMJ 323 (7321): 1123‚Äì24. https://doi.org/10.1136/bmj.323.7321.1123.\n\n\n\n\n",
      "last_modified": "2022-12-20T17:30:50+01:00"
    },
    {
      "path": "immortal.html",
      "title": "Immortal time bias",
      "author": [
        {
          "name": "Andr√© Moser, CTU Bern, University of Bern",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nReview\nOpen tasks\nBackground\nExample\nKnowledge from the\ncrystal ball\n\nAnalysis strategy\nDescriptive table\nMethod 1: Group\nassignment at time zero\nMethod 2:\nRandom time to treatment assignment\nMethod 3:\nMatched time to treatment assignment\nMethod 4: Time\nzero at end of treatment\nMethod 5:\nTime-dependent treatment\nMethod 6: Cloning\n\nConclusion\nData simulation\n\nReview\nThis vignette has not been reviewed (yet) by other statisticians üò±.\nüíÄ You read it on your own risk üíÄ.\nOpen tasks\nMore realistic assumptions: People can die in treatment period.\nStart of time zero possible hospital admission? Other examples?\nDefine specific time at end of treatment and not median time\nDecrease sample size\nBackground\nImmortal time bias might arise, if - for example - individuals are\nassigned to an exposure or treatment group based on covariate\ninformation after time zero (Hern√°n et al. (2016)). Consequently, group assignment\nis not aligned with time zero and individuals inherently experience no\noutcome event for a specific time period (they are immortal when the\noutcome of interest is time to death). Immortal time bias is common when\nanalyzing observational studies (Suissa (2007), L√©vesque et al. (2010)). Other terminology for immortal\ntime bias is time dependent bias or survival bias. In\nthis vignette we introduce several methods to address immortal time bias\ndiscussed in the articles by Zhou et al. (2005) and Hern√°n and Robins (2016).\nExample\nWe consider a study population of 10,000 patients admitted to an\nemergency unit. Patients with a more severe admission status are treated\nmore quickly. Clinicians are interested whether the time from admission\nto time to treatment affect survival and group patients into two\ntreatment groups: Short and long time to treatment after emergency\nadmission. Group assignment is based on the median time to\ntreatment.\nResearch question: What is the effect of the time to\ntreatment group assignment on survival?\nStudy design: Cohort study\nOutcome of interest: Time to death or end of follow-up\nObservation time: Admission to end of follow-up\nPredictor of interest: Time to treatment after admission\nConfounders: Severity\nThe used variables from the data are:\nVariable\nDefinition\nCoding\ngroup\nGroup assignment\n1=Long (exposed), 0=Short (unexposed)\nseverity\nSeverity status\n1=Severe, 0=Non-severe\ndeath\nDeath\n1=Death, 0=Alive\ntime_to_treatment\nTime to treatment (days)\nNon-negative number\nfup\nFollow-up time (days)\nNon-negative number\nKnowledge from the crystal\nball\nBecause we simulated the data, we know that group assignment has no\neffect on mortality.\nAnalysis strategy\nZhou et al. (2005), Karim et al. (2016), Maringe et al. (2020), Hern√°n and Robins (2016) and Hern√°n et al. (2016) discuss different analysis\nstrategies for addressing (or not addressing) immortal time bias. In\nthis vignette we summarize the investigated methods from the above\nmentioned articles:\nMethod\nDefinition\n1\nGroup assignment at time zero\n2\nRandom time to treatment assignment\n3\nMatched time to treatment assignment\n4\nTime zero at end of treatment\n5\nTime dependent treatment\n6\nCloning\n\n\n# Required packages\nlibrary(tidyverse)\nlibrary(survey)\nlibrary(survival)\nlibrary(survminer)\n\n\n\n\n\n\n\n\n\nDescriptive table\nThe table below shows a descriptive summary of the study population,\nby group assignment.\n\n\n\n\n\nCharacteristic\n      Short, N = 5,0001\n      Long, N = 5,0001\n    fup\n15 (11, 22)\n18 (14, 25)time_to_treatment\n7.74 (6.63, 8.60)\n10.66 (9.97, 11.59)death\n2,512 (50%)\n2,471 (49%)severity\n3,991 (80%)\n2,221 (44%)1 Median (IQR); n (%)\n    \n\n\n\n\n\n\n\nMethod 1: Group\nassignment at time zero\nTime zero was time of emergency admission. Treatment was assigned\naccording to whether patients had a short or long time to treatment. No\npatients were excluded from the analysis.\n\n\n# Kaplan-Meier survival curves\nmod <- survfit(Surv(fup, death)~factor(group), data=data)\nggsurvplot(mod, data=data, palette=c(\"#CC0000\", \"black\"), censor=F, pval=T, xlab=\"Days from emergency admission\")\n\n\n\n\nMethod 2: Random\ntime to treatment assignment\nTreatment was assigned according to whether patients had a short or\nlong time to treatment. Time zero was set at start of treatment, but\ntime to treatment for the short group was randomly replaced by a time to\ntreatment from the time to treatment range of the long group.\n\n\ndata_method2 <- data\n\n# New time to treament for short group\ndata_method2$time_to_treatment_new <- data_method2$time_to_treatment\ndata_method2$time_to_treatment_new[data_method2$group==0] <- \n  runif(sum(data_method2$group==0), median(time_to_treatment), max(time_to_treatment))\n\n# Exclusion of patients:\n# If original follow-up time of patients < random treatment time\ndata_method2$exclude <- 0\n# Patients in the short group who died\nid_short <- data_method2$group==0 & data_method2$death==1\ndata_method2$exclude[data_method2$group==0 & data_method2$death==1] <- \n  ifelse(data_method2$fup[id_short]<data_method2$time_to_treatment_new[id_short], 1, 0)\n\n\n\n930 (9.3%) individuals from the short group who died before time zero\nwere excluded.\n\n\ndata_method2 <- data_method2 %>% filter(exclude==0)\n\n# Time zero: Start of treatment\n# Difference between new random treatment time - original treatment time (=zero for long group)\ndata_method2$fup <- pmin(data_method2$time_to_treatment_new-data_method2$time_to_treatment+data_method2$time_to_death, \n                         data_method2$time_to_treatment_new-data_method2$time_to_treatment+data_method2$censored)\n# Replace death indicator\ndata_method2$death <- ifelse(data_method2$time_to_treatment_new-data_method2$time_to_treatment+data_method2$time_to_death<=\n                               data_method2$time_to_treatment_new-data_method2$time_to_treatment+data_method2$censored, 1, 0)\n\n# Kaplan-Meier survival curves\nmod <- survfit(Surv(fup, death)~factor(group), data=data_method2)\nggsurvplot(mod, data=data_method2, palette=c(\"#CC0000\", \"black\"), censor=F, pval=T, xlab=\"Days from start of treatment\")\n\n\n\n\nMethod 3: Matched\ntime to treatment assignment\nTreatment was assigned according to whether patients had a short or\nlong time to treatment. Time zero was set at start of treatment, but\ntime to treatment for the short group was randomly replaced by a time to\ntreatment from the time to treatment range of the long group. This\nmethods corrects for time to treatment imbalances between the two groups\n(in contrast to method 2).\n\n\ndata_method3 <- data\n# Get time to treatment from long group\nsample_time <- data_method3$time_to_treatment[data_method3$group==1]\n# New time to treatment for short group: Matching from long group\ndata_method3$time_to_treatment_new <- data_method3$time_to_treatment\ndata_method3$time_to_treatment_new[data_method3$group==0] <- \n  sample(sample_time, length(data_method3$time_to_treatment[data_method3$group==0]))\n\n# Exclusion of patients\ndata_method3$exclude <- 0\ndata_method3$exclude[data_method3$group==0 & data_method3$death==1] <- \n  ifelse(data_method3$fup[data_method3$group==0 & data_method3$death==1]<\n           data_method3$time_to_treatment_new[data_method3$group==0 & data_method3$death==1], 1, 0)\n\n\n\n686 (6.9%) individuals from the short group who die before time zero\nwere excluded.\n\n\ndata_method3 <- data_method3 %>% filter(exclude==0)\n\n# Time zero: Start of treatment\n# Difference between new matched treatment time - original treatment time (=zero for long group)\ndata_method3$fup <- pmin(data_method3$time_to_treatment_new-data_method3$time_to_treatment+data_method3$time_to_death, \n                         data_method3$time_to_treatment_new-data_method3$time_to_treatment+data_method3$censored)\ndata_method3$fup <- pmin(data_method3$time_to_death, data_method3$censored)\n# Replace death indicator\ndata_method3$death <- ifelse(data_method3$time_to_treatment_new-data_method3$time_to_treatment+data_method3$time_to_death<=\n                               data_method3$time_to_treatment_new-data_method3$time_to_treatment+data_method3$censored, 1, 0)\n\n# Kaplan-Meier survival curves\nmod <- survfit(Surv(fup, death)~factor(group), data=data_method3)\nggsurvplot(mod, data=data_method3, palette=c(\"#CC0000\", \"black\"), censor=F, \n           pval=T, xlab=\"Days from start of treatment\")\n\n\n\n\nMethod 4: Time zero at\nend of treatment\nTreatment was assigned according to whether patients had a short or\nlong time to treatment. End of treatment was defined at the last\nobserved time to treatment (15.6 days). Individuals were followed-up\nfrom the end of treatment duration (time zero).\n\n\ndata_method4 <- data\ndata_method4$exclude <- ifelse(data_method4$fup<max(time_to_treatment), 1, 0)\n\n\n\n4517 (45.2%) individuals from both groups with a follow-uo time\nsmaller than end of treatment duration were excluded.\n\n\ndata_method4 <- data_method4 %>% filter(exclude==0)\n# Shift time to follow-up\ndata_method4$fup <- data_method4$fup-max(time_to_treatment)\n\n# Kaplan-Meier survival curves\nmod <- survfit(Surv(fup, death)~factor(group), data=data_method4)\nggsurvplot(mod, data=data_method4, palette=c(\"#CC0000\", \"black\"), censor=F, \n           pval=T, xlab=\"Days from end of treatment duration\")\n\n\n\n\nMethod 5: Time-dependent\ntreatment\nTreatment assignment was 0 (‚Äúshort‚Äù) as long as a patient had a time\nto treatment smaller than the median time to treatment, and 1 (‚Äúlong‚Äù)\notherwise. No individuals were excluded.\n\n\nlibrary(splitstackshape)\n# For \"smoother\" curves: Fup*10\nmultiplier <- 10\ndata$fup2 <- data$fup*multiplier\ndata_discrete_surv <- expandRows(data, count=\"fup2\", drop=F) %>% arrange(id)\n# Count indicator: How many follow-up days per individuals\ndata_discrete_surv <- data_discrete_surv %>% group_by(id) %>% mutate(ind=1, time=cumsum(ind)-1)\ndata_discrete_surv$ind <- NULL\n# Maximal follow-up day\ndata_discrete_surv <- data_discrete_surv %>% group_by(id) %>% mutate(max_time=max(time))\n# Correct death\ndata_discrete_surv$death[data_discrete_surv$time < data_discrete_surv$max_time] <- 0\n# Shift days\ndata_discrete_surv <- data_discrete_surv %>% group_by(id) %>% mutate(time2=lead(time))\n# Fill last day\ndata_discrete_surv <- data_discrete_surv %>% group_by(id) %>% fill(time2)\ndata_discrete_surv$time2[data_discrete_surv$time==data_discrete_surv$max_time] <- \n  data_discrete_surv$time2[data_discrete_surv$time==data_discrete_surv$max_time]+1\n\n# Create time-dependent treatment\ndata_discrete_surv <- data_discrete_surv %>% group_by(id) %>% mutate(group_timedependent=0)\ndata_discrete_surv$group_timedependent[data_discrete_surv$time>=\n            data_discrete_surv$time_to_treatment*multiplier & data_discrete_surv$group==1] <- 1\n# Kaplan-Meier survival curves\nmod_km <- survfit(Surv(time=time/multiplier, time2=time2/multiplier, event=death)~\n                    group_timedependent, data=data_discrete_surv, cluster = id)\nggsurvplot(mod_km, data=data_discrete_surv, palette=c(\"#CC0000\", \"black\"), \n           censor=F, pval=F, xlab=\"Days from emergency admission\")\n\n\n\n# Cox model\ncox_fit <- coxph(Surv(time=time/multiplier, time2=time2/multiplier, event=death)~\n                   group_timedependent, data=data_discrete_surv, cluster = id)\n\n\n\nThe p-value from a Cox proportional hazard model comparing the two\nsurvival curves was p=0.022 (p-value from Schoenfeld test p=0.003).\nMethod 6: Cloning\nEach patient received the actual observed exposure or treatment and\nwas cloned, receiving the not observed exposure or treatment. This led\nto two pseudopopulations, each with a size of 10^{4}` patients. Patients\nin one pseudopopulation (those having a short time to treatment\nduration) were censored if the time to treatment is longer than the\nmedian time to treatment. Patients in the pseudopopulation with a long\ntime to treatment duration were censored if patients were alive and had\na time to treatment shorter than the median time to treatment. Censoring\ncan be seen as a protocol deviation (Maringe et al. (2020)). Artificial censoring is\naddressed by inverse probability weighting (Hern√°n and Robins (2016), Hern√°n et al. (2016)). No patients were excluded from\nthe analysis.\n\n\n\nThe p-value from a Cox proportional hazard model comparing the two\nsurvival curves was p=0.017 (p-value from Schoenfeld test p=0.986).\nConclusion\nImmortal time bias is common in time to event analysis of\nobservational data. In the present vignette we presented several methods\nfor addressing immortal time bias. Similar to Zhou et al. (2005) we conclude that the investigated\nmethods 1 and 2 did not adequately address immortal time bias. In\ncontrast to Zhou et al. (2005) we found that\nmethod 3 did not adequately address immortal time bias too, which was\nalso highlighted in Karim et\nal. (2016). Methods\n4 to 6 were able to address immortal time bias. We recommend to compare\nsome of the suggested methods in a real world analysis in sensitivity\nanalyses and to be aware of their limitations (for example, exclusion of\npatients which leads to selection bias).\nData simulation\n\n\nn <- 10000\n\nset.seed(1)\n\n# Time to treatment: Mean 10 days\ntime_to_treatment <- rweibull(n, 5, 10)\n# Two equal groups based on time to treatment\ngroup <- ifelse(time_to_treatment>median(time_to_treatment), 1, 0)\n# More severe patients are treated more quickly\nseverity <- ifelse(runif(n)<plogis(qlogis(0.8)+log(0.2)*(group==1)), 1, 0)\n# Hazard of dying: Independent of time to treatment and severity\nhaz <- 0.05\n# Time to death: Exponential with rate=haz\ntime_to_death <- -log(runif(n))/haz\n# Censoring: Mean 20 days\ncensored <- rweibull(n, 1, 20)\n# Follow-up time: Patients do not die until they are treated\nfup <- pmin(time_to_treatment+time_to_death, time_to_treatment+censored)\n# Death indicator: Patients do not die until they are treated\ndeath <- ifelse(time_to_treatment+time_to_death<=time_to_treatment+censored, 1, 0)\n# Data\ndata <- data.frame(id=1:n, fup, time_to_treatment, censored, time_to_death, death, group, severity)\n\n\n\n\n\n\nHern√°n, Miguel A., and James M. Robins. 2016. ‚ÄúUsing Big Data to Emulate a Target Trial When a\nRandomized Trial Is Not Available.‚Äù American Journal\nof Epidemiology 183 (8): 758‚Äì64. https://doi.org/10.1093/aje/kwv254.\n\n\nHern√°n, Miguel A., Brian C. Sauer, Sonia Hern√°ndez-D√≠az, Robert Platt,\nand Ian Shrier. 2016. ‚ÄúSpecifying a Target Trial Prevents Immortal\nTime Bias and Other Self-Inflicted Injuries in Observational\nAnalyses.‚Äù Journal of Clinical Epidemiology 79: 70‚Äì75.\nhttps://doi.org/https://doi.org/10.1016/j.jclinepi.2016.04.014.\n\n\nKarim, Mohammad Ehsanul, Paul Gustafson, John Petkau, Helen Tremlett,\nthe Long-Term Benefits, Adverse Effects of Beta-Interferon for Multiple\nSclerosis (BeAMS) Study Group, Mohammad Ehsanul Karim, et al. 2016.\n‚ÄúComparison of Statistical Approaches for\nDealing With Immortal Time Bias in Drug Effectiveness\nStudies.‚Äù American Journal of Epidemiology 184\n(4): 325‚Äì35. https://doi.org/10.1093/aje/kwv445.\n\n\nL√©vesque, Linda E, James A Hanley, Abbas Kezouh, and Samy Suissa. 2010.\n‚ÄúProblem of Immortal Time Bias in Cohort Studies: Example Using\nStatins for Preventing Progression of Diabetes.‚Äù BMJ\n340. https://doi.org/10.1136/bmj.b5087.\n\n\nMaringe, Camille, Sara Benitez Majano, Aimilia Exarchakou, Matthew\nSmith, Bernard Rachet, Aur√©lien Belot, and Cl√©mence Leyrat. 2020.\n‚ÄúReflection on modern methods: trial\nemulation in the presence of immortal-time bias. Assessing the benefit\nof major surgery for elderly lung cancer patients using observational\ndata.‚Äù International Journal of Epidemiology 49\n(5): 1719‚Äì29. https://doi.org/10.1093/ije/dyaa057.\n\n\nSuissa, Samy. 2007. ‚ÄúImmortal Time Bias in Observational Studies\nof Drug Effects.‚Äù Pharmacoepidemiology and Drug Safety\n16 (3): 241‚Äì49. https://doi.org/https://doi.org/10.1002/pds.1357.\n\n\nZhou, Zheng, Elham Rahme, Michal Abrahamowicz, and Louise Pilote. 2005.\n‚ÄúSurvival Bias Associated with\nTime-to-Treatment Initiation in Drug Effectiveness Evaluation: A\nComparison of Methods.‚Äù American Journal of\nEpidemiology 162 (10): 1016‚Äì23. https://doi.org/10.1093/aje/kwi307.\n\n\n\n\n",
      "last_modified": "2022-06-14T09:30:08+02:00"
    },
    {
      "path": "index.html",
      "title": "Vignettes",
      "description": "",
      "author": [],
      "contents": "\nClick on the upper right button for topic selection.\n\n\n\n",
      "last_modified": "2022-12-19T13:18:12+01:00"
    }
  ],
  "collections": []
}
